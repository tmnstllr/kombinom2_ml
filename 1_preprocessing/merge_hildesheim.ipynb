{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from fiona.crs import from_epsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "csv = \"combined_data_MP_NE_dT_cC_Coord.csv\"\n",
    "df_csv = pd.read_csv(csv)\n",
    "df_csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shapefile_path = 'hildesheim_merged.shp'\n",
    "gdf_shape = gpd.read_file(shapefile_path)\n",
    "gdf_shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create Point geometries from coordinates\n",
    "df_csv['StartPoint'] = df_csv.apply(lambda row: Point(row['startLon'], row['startLat']), axis=1)\n",
    "df_csv['EndPoint'] = df_csv.apply(lambda row: Point(row['endLon'], row['endLat']), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create separate GeoDataFrames for start and end points\n",
    "gdf_start = gpd.GeoDataFrame(df_csv, geometry='StartPoint', crs=from_epsg(4326))\n",
    "gdf_end = gpd.GeoDataFrame(df_csv, geometry='EndPoint', crs=from_epsg(4326))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reproject the shapefile to match the CRS of the GeoDataFrames\n",
    "gdf_shape = gdf_shape.to_crs(gdf_start.crs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Perform spatial join to filter rows where both start and end points are inside the shapefile\n",
    "gdf_start_inside = gpd.sjoin(gdf_start, gdf_shape, op='intersects', how='inner')\n",
    "gdf_end_inside = gpd.sjoin(gdf_end, gdf_shape, op='intersects', how='inner')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gdf_start_inside"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gdf_end_inside"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_result = gdf_start_inside.merge(gdf_end_inside, how='inner', on=['year', 'month', 'startClusterName', 'startClusterZip', 'startClusterID', 'startID', 'endClusterName', 'endClusterZip', 'endClusterID', 'endID', 'weekday', 'daytime', 'isSchoolHoliday', 'distance', 'count', 'count_corrected', 'startLon', 'startLat', 'endLon', 'endLat'])\n",
    "df_result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_result.drop(columns=['StartPoint_x', 'StartPoint_y', 'index_right_x', 'id_x', 'index_right_y', 'id_y'], inplace=True)\n",
    "df_result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_result.drop(columns=['EndPoint_x', 'EndPoint_y'], inplace=True)\n",
    "df_result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_result.to_csv('combined_data_MP_NE_hildesheim_merged_Coord' + '.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# new try"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shapefile_path = 'hildesheim_merged.shp'\n",
    "gdf_shape = gpd.read_file(shapefile_path)\n",
    "gdf_shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "csv_shapes = \"desd-4-landkreis-hildesheim-1663168323029-shapes.csv\"\n",
    "df_shapes = pd.read_csv(csv_shapes)\n",
    "df_shapes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_shapes['StartPoint'] = df_shapes.apply(lambda row: Point(row['lon'], row['lat']), axis=1)\n",
    "df_shapes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gdf_shapes = gpd.GeoDataFrame(df_shapes, geometry='StartPoint', crs=from_epsg(4326))\n",
    "gdf_shapes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reproject the shapefile to match the CRS of the GeoDataFrames\n",
    "gdf_shape = gdf_shape.to_crs(gdf_shapes.crs)\n",
    "gdf_shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gdf_shapes_inside = gpd.sjoin(gdf_shapes, gdf_shape, op='intersects', how='inner')\n",
    "gdf_shapes_inside"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gdf_shapes_inside['FID'] = gdf_shapes_inside['FID'].astype(str).apply(lambda x: x.split('_')[0])\n",
    "gdf_shapes_inside"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_names = gdf_shapes_inside['FID'].unique()\n",
    "unique_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gdf_unique_names = gdf_shapes_inside[~gdf_shapes_inside['FID'].duplicated(keep=\"first\")]\n",
    "gdf_unique_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "csv = \"combined_data_MP_NE_dT_cC_Coord.csv\"\n",
    "df_csv = pd.read_csv(csv)\n",
    "df_csv['startClusterID'] = df_csv['startClusterID'].astype(str)\n",
    "df_csv['endClusterID'] = df_csv['endClusterID'].astype(str)\n",
    "#df_csv.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "condition1 = df_csv['startClusterID'].isin(unique_names)\n",
    "condition2 = df_csv['endClusterID'].isin(unique_names)\n",
    "df_filtered = df_csv[condition1 & condition2]\n",
    "df_filtered"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_cluster_ids = df_filtered['startClusterID'].unique()\n",
    "end_cluster_ids = df_filtered['endClusterID'].unique()\n",
    "union_ids = np.union1d(start_cluster_ids, end_cluster_ids)\n",
    "union_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_filtered.to_csv(csv.split('.')[0] + '_hildesheimMerged.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# group and sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Group the data by 'StartName' and 'EndName' and calculate the sum of 'count' for each group\n",
    "grouped_data = df_filtered.groupby(['startClusterID', 'startClusterName']).agg({\n",
    "    'count': 'sum',\n",
    "    'startLon': 'first',\n",
    "    'startLat': 'first',\n",
    "}).reset_index()\n",
    "# Sort the data by the sum of count in descending order to get the most trafficked routes\n",
    "grouped_data = grouped_data.sort_values(by='count', ascending=False)\n",
    "grouped_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_data.to_csv(csv.split(\".\")[0] + \"_hildesheimMerged_sumCountPerStartClusterID.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.rc_file_defaults()\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "# Set the font family to Arial\n",
    "mpl.rcParams['font.family'] = 'sans-serif'\n",
    "mpl.rcParams['font.sans-serif'] = ['Arial']\n",
    "\n",
    "dpi = 500\n",
    "font_title = 16\n",
    "font_label = 15\n",
    "font_chart = 13\n",
    "weight_label = 'bold'\n",
    "weight_title = 'bold'\n",
    "pad_label = 10\n",
    "alpha = 0.7"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the total count of all combinations\n",
    "total_count = grouped_data['count'].sum()\n",
    "\n",
    "# Create a horizontal bar chart\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.bar(grouped_data['startClusterID'], grouped_data['count'], color='skyblue')\n",
    "\n",
    "\n",
    "# Add a vertical line at the 30th percentile\n",
    "plt.axvline(x=92, color='red', linestyle='--', label='30th Percentile', alpha=alpha)\n",
    "\n",
    "# Highlight the region around the 30th percentile\n",
    "plt.axvspan(xmin=92, xmax=132, color='red', alpha=0.05, label='Bottom 30%')\n",
    "\n",
    "# Set axis labels and title\n",
    "plt.xlabel('Cluster (sorted in descending order) ', fontsize=font_label, fontweight=weight_label, labelpad=pad_label)\n",
    "plt.ylabel('Number of Trips', fontsize=font_label, fontweight=weight_label, labelpad=pad_label)\n",
    "plt.title('Distribution of the Number of Trips per Cluster (log10 scaled)', fontsize=font_title, fontweight=weight_title, va='bottom')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=1)\n",
    "plt.yticks(fontsize=font_chart)\n",
    "plt.gca().get_yaxis().get_offset_text().set_visible(False)\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylim(1, 1e7)\n",
    "plt.legend(fontsize=font_chart)\n",
    "\n",
    "# Save the plots as PNG images\n",
    "plt.savefig('/Users/timon/Documents/ba/abbildungen/' + csv.split('.')[0] + '__DistributionOfCountAcrossCluster_log.png', dpi=dpi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate normalized counts\n",
    "normalized_counts = grouped_data['count'] / grouped_data['count'].sum()\n",
    "\n",
    "# Create a histogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "# Create the histogram\n",
    "plt.bar(grouped_data['startClusterID'], normalized_counts, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add a vertical line at the 30th percentile\n",
    "plt.axvline(x=92, color='red', linestyle='--', label='30th Percentile')\n",
    "\n",
    "# Set axis labels and title\n",
    "plt.xlabel('Cluster (sorted in descending order)', fontsize=font_label, fontweight=weight_label, labelpad=pad_label)\n",
    "plt.ylabel('Normalized Count', fontsize=font_label, fontweight=weight_label, labelpad=pad_label)\n",
    "plt.title('Distribution of Normalized Cluster Frequencies', fontsize=font_title, fontweight=weight_title)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=1)\n",
    "plt.yticks(fontsize=font_chart)\n",
    "plt.gca().get_yaxis().get_offset_text().set_visible(False)\n",
    "\n",
    "plt.legend(fontsize=font_chart)\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "#plt.savefig('/Users/timon/Documents/ba/abbildungen/' + csv.split('.')[0] + '__DistributionOfNormalizedClusterFrequencies.png', dpi=dpi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.percentile(normalized_counts, 1) * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.percentile(grouped_data['count'], 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the 30th percentile of normalized counts\n",
    "percentile_30 = np.percentile(normalized_counts, 30) # top 1: 99.242424\n",
    "\n",
    "# Calculate the sum of normalized counts for the bottom 30%\n",
    "sum_bottom_30_percentage = round(np.sum(normalized_counts[normalized_counts <= percentile_30]) * 100, 4)\n",
    "sum_bottom_30_percentage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_data['count'].describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
